#!/usr/bin/env python3
"""
é…ç½®é©±åŠ¨åŠ©æ‰‹æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„é…ç½®æ–‡ä»¶åˆ›å»ºä¸“ä¸šåŒ–çš„AIåŠ©æ‰‹
"""

import asyncio
import os
from config_driven_assistant import ConfigDrivenAssistant

async def demo_config_validation():
    """æ¼”ç¤ºé…ç½®éªŒè¯åŠŸèƒ½"""
    print("ğŸ” é…ç½®éªŒè¯æ¼”ç¤º")
    print("=" * 50)
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶åˆ—è¡¨
    config_files = [
        "assistant_config.toml",
        "python_assistant.toml", 
        "creative_assistant.toml",
        "business_assistant.toml"
    ]
    
    for config_file in config_files:
        if os.path.exists(config_file):
            try:
                print(f"\nğŸ“ åŠ è½½é…ç½®: {config_file}")
                assistant = ConfigDrivenAssistant(config_file)
                info = assistant.get_info()
                
                print(f"   âœ… åŠ©æ‰‹åç§°: {info['name']}")
                print(f"   ğŸ“ æè¿°: {info['description']}")
                print(f"   ğŸ¤– æ¨¡å‹: {info['model']}")
                print(f"   ğŸŒ¡ï¸  æ¸©åº¦: {info['temperature']}")
                print(f"   ğŸ“Š æœ€å¤§å†å²: {info['max_history']}")
                
            except Exception as e:
                print(f"   âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        else:
            print(f"\nğŸ“ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

async def demo_pydantic_validation():
    """æ¼”ç¤ºPydanticæ•°æ®éªŒè¯"""
    print("\n\nğŸ›¡ï¸ Pydanticæ•°æ®éªŒè¯æ¼”ç¤º")
    print("=" * 50)
    
    from config_driven_assistant import LLMConfig, AssistantConfig
    
    # æµ‹è¯•æœ‰æ•ˆé…ç½®
    print("\n1ï¸âƒ£ æµ‹è¯•æœ‰æ•ˆé…ç½®")
    try:
        llm_config = LLMConfig(
            model=os.getenv("OPENAI_API_MODEL", "gpt-3.5-turbo"),
            temperature=0.7,
            max_tokens=1000
        )
        print(f"   âœ… LLMé…ç½®åˆ›å»ºæˆåŠŸ: {llm_config.model}")
    except Exception as e:
        print(f"   âŒ LLMé…ç½®åˆ›å»ºå¤±è´¥: {e}")
    
    # æµ‹è¯•æ— æ•ˆæ¸©åº¦
    print("\n2ï¸âƒ£ æµ‹è¯•æ— æ•ˆæ¸©åº¦å‚æ•°")
    try:
        invalid_config = LLMConfig(
            model=os.getenv("OPENAI_API_MODEL", "gpt-3.5-turbo"),
            temperature=3.0,  # è¶…å‡ºèŒƒå›´
            max_tokens=1000
        )
        print(f"   âŒ åº”è¯¥å¤±è´¥ä½†æˆåŠŸäº†: {invalid_config.temperature}")
    except Exception as e:
        print(f"   âœ… æ­£ç¡®æ•è·éªŒè¯é”™è¯¯: {e}")
    
    # æµ‹è¯•æ— æ•ˆtokenæ•°
    print("\n3ï¸âƒ£ æµ‹è¯•æ— æ•ˆtokenæ•°")
    try:
        invalid_config = LLMConfig(
            model=os.getenv("OPENAI_API_MODEL", "gpt-3.5-turbo"),
            temperature=0.7,
            max_tokens=0  # å°äºæœ€å°å€¼
        )
        print(f"   âŒ åº”è¯¥å¤±è´¥ä½†æˆåŠŸäº†: {invalid_config.max_tokens}")
    except Exception as e:
        print(f"   âœ… æ­£ç¡®æ•è·éªŒè¯é”™è¯¯: {e}")

async def demo_different_assistants():
    """æ¼”ç¤ºä¸åŒç±»å‹çš„åŠ©æ‰‹"""
    print("\n\nğŸ­ ä¸åŒåŠ©æ‰‹ç±»å‹æ¼”ç¤º")
    print("=" * 50)
    
    # æµ‹è¯•é—®é¢˜
    test_questions = {
        "python_assistant.toml": "å¦‚ä½•ä½¿ç”¨Pythonåˆ›å»ºä¸€ä¸ªç®€å•çš„Web APIï¼Ÿ",
        "creative_assistant.toml": "å¸®æˆ‘å†™ä¸€ä¸ªå…³äºæœªæ¥åŸå¸‚çš„çŸ­ç¯‡æ•…äº‹å¼€å¤´",
        "business_assistant.toml": "åˆ†æä¸€ä¸‹ç”µå•†è¡Œä¸šçš„å‘å±•è¶‹åŠ¿"
    }
    
    for config_file, question in test_questions.items():
        if os.path.exists(config_file):
            try:
                print(f"\nğŸ¤– ä½¿ç”¨é…ç½®: {config_file}")
                assistant = ConfigDrivenAssistant(config_file)
                info = assistant.get_info()
                print(f"   åŠ©æ‰‹: {info['name']}")
                print(f"   é—®é¢˜: {question}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰APIå¯†é’¥
                api_key = os.getenv('OPENAI_API_KEY')
                if api_key and api_key != 'your_openai_api_key_here':
                    print("   æ­£åœ¨ç”Ÿæˆå›å¤...")
                    response = await assistant.process_message(question)
                    print(f"   å›å¤: {response[:200]}...")
                else:
                    print("   ğŸ’¡ éœ€è¦é…ç½®OPENAI_API_KEYè¿›è¡Œå®é™…æµ‹è¯•")
                    
            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")

async def demo_config_features():
    """æ¼”ç¤ºé…ç½®åŠŸèƒ½ç‰¹æ€§"""
    print("\n\nâš™ï¸ é…ç½®åŠŸèƒ½ç‰¹æ€§æ¼”ç¤º")
    print("=" * 50)
    
    if os.path.exists("assistant_config.toml"):
        try:
            assistant = ConfigDrivenAssistant("assistant_config.toml")
            
            print("\n1ï¸âƒ£ åŠ©æ‰‹ä¿¡æ¯")
            info = assistant.get_info()
            for key, value in info.items():
                print(f"   {key}: {value}")
            
            print("\n2ï¸âƒ£ å¯¹è¯å†å²ç®¡ç†")
            print(f"   åˆå§‹å†å²é•¿åº¦: {assistant.get_history_length()}")
            
            # æ¨¡æ‹Ÿæ·»åŠ æ¶ˆæ¯
            assistant.conversation_history.append({"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯1"})
            assistant.conversation_history.append({"role": "assistant", "content": "æµ‹è¯•å›å¤1"})
            print(f"   æ·»åŠ æ¶ˆæ¯å: {assistant.get_history_length()}")
            
            # æ¸…ç©ºå†å²
            assistant.clear_history()
            print(f"   æ¸…ç©ºå: {assistant.get_history_length()}")
            
            print("\n3ï¸âƒ£ é…ç½®é‡è½½")
            assistant.reload_config()
            
        except Exception as e:
            print(f"âŒ åŠŸèƒ½æ¼”ç¤ºå¤±è´¥: {e}")

async def main():
    """ä¸»æ¼”ç¤ºç¨‹åº"""
    print("ğŸš€ é…ç½®é©±åŠ¨åŠ©æ‰‹ - åŠŸèƒ½æ¼”ç¤º")
    print("åŸºäºé¡¹ç›®1çš„åŸºç¡€ï¼Œå±•ç¤ºPydanticå’ŒTOMLé…ç½®çš„å¼ºå¤§åŠŸèƒ½")
    print("=" * 70)
    
    # è¿è¡Œå„ç§æ¼”ç¤º
    await demo_config_validation()
    await demo_pydantic_validation()
    await demo_different_assistants()
    await demo_config_features()
    
    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ’¡ å­¦ä¹ è¦ç‚¹æ€»ç»“:")
    print("   â€¢ Pydanticæä¾›å¼ºå¤§çš„æ•°æ®éªŒè¯åŠŸèƒ½")
    print("   â€¢ TOMLé…ç½®æ–‡ä»¶æ˜“äºé˜…è¯»å’Œç»´æŠ¤")
    print("   â€¢ é…ç½®é©±åŠ¨å¼€å‘æé«˜äº†ä»£ç çš„çµæ´»æ€§")
    print("   â€¢ ä¸åŒé…ç½®å¯ä»¥åˆ›å»ºä¸“ä¸šåŒ–çš„åŠ©æ‰‹")
    print("   â€¢ ç±»å‹å®‰å…¨å’Œé”™è¯¯å¤„ç†è®©ç¨‹åºæ›´å¥å£®")

if __name__ == "__main__":
    asyncio.run(main())