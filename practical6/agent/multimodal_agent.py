"""
å¤šæ¨¡æ€ä»£ç† - æ ¸å¿ƒå®ç°

åŸºäºReActæ¨ç†æ¨¡å¼çš„å¤šæ¨¡æ€æ™ºèƒ½ä»£ç†ï¼Œæ‰©å±•æ”¯æŒå›¾åƒå¤„ç†å’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–ã€‚

æ‰©å±•åŠŸèƒ½ï¼š
1. å¤šæ¨¡æ€è¾“å…¥å¤„ç†ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰
2. æ™ºèƒ½ä»»åŠ¡åˆ†è§£å’Œå·¥å…·é€‰æ‹©
3. å›¾åƒåˆ†æå’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–
4. å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ç®¡ç†

å­¦ä¹ è¦ç‚¹ï¼š
- ç»§æ‰¿å’Œæ‰©å±•ç°æœ‰ç±»
- å¤šæ¨¡æ€æ•°æ®å¤„ç†
- å¤æ‚ä»»åŠ¡çš„åˆ†è§£ç­–ç•¥
- å·¥å…·åè°ƒå’Œç»“æœæ•´åˆ
"""

import asyncio
import json
import re
import time
import logging
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Union, Tuple
from pathlib import Path
from PIL import Image
import openai
from openai import AsyncOpenAI

# å¯¼å…¥practical5çš„åŸºç¡€ç»„ä»¶
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..', 'practical5'))

from practical5.agent.react_agent import ReActAgent, AgentState, ReActStep
from practical5.tools.manager import ToolManager
from practical5.tools.base import BaseTool, ToolResult

# å¯¼å…¥å¤šæ¨¡æ€å·¥å…·
from ..tools.multimodal_base import MultimodalTool, MultimodalInput
from ..tools.image_analyzer import ImageAnalyzer
from ..tools.browser_automation import BrowserTool
from ..utils.config import Config
from ..utils.logger import setup_logger

logger = logging.getLogger(__name__)


class MultimodalTaskType(str, Enum):
    """å¤šæ¨¡æ€ä»»åŠ¡ç±»å‹"""
    IMAGE_ANALYSIS = "image_analysis"           # çº¯å›¾åƒåˆ†æ
    WEB_AUTOMATION = "web_automation"           # çº¯ç½‘é¡µè‡ªåŠ¨åŒ–
    MULTIMODAL_SEARCH = "multimodal_search"     # å›¾åƒ+ç½‘é¡µæœç´¢
    VISUAL_WEB_TASK = "visual_web_task"         # è§†è§‰å¼•å¯¼çš„ç½‘é¡µæ“ä½œ
    GENERAL = "general"                         # é€šç”¨ä»»åŠ¡


@dataclass
class MultimodalStep(ReActStep):
    """
    å¤šæ¨¡æ€æ¨ç†æ­¥éª¤
    
    æ‰©å±•ReActStepä»¥æ”¯æŒå¤šæ¨¡æ€ä¿¡æ¯ã€‚
    """
    image_data: Optional[str] = None            # å›¾åƒæ•°æ®ï¼ˆBase64ï¼‰
    task_type: str = "general"                  # ä»»åŠ¡ç±»å‹
    multimodal_context: Dict[str, Any] = field(default_factory=dict)  # å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        base_dict = super().to_dict()
        base_dict.update({
            'image_data': self.image_data,
            'task_type': self.task_type,
            'multimodal_context': self.multimodal_context
        })
        return base_dict


class MultimodalAgent(ReActAgent):
    """
    å¤šæ¨¡æ€ä»£ç†
    
    ç»§æ‰¿ReActä»£ç†ï¼Œæ‰©å±•å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›ã€‚
    
    å­¦ä¹ è¦ç‚¹ï¼š
    - ç±»çš„ç»§æ‰¿å’Œæ–¹æ³•é‡å†™
    - å¤šæ¨¡æ€æ•°æ®çš„ç»Ÿä¸€å¤„ç†
    - å¤æ‚ç³»ç»Ÿçš„æ¶æ„è®¾è®¡
    - å¼‚æ­¥ç¼–ç¨‹çš„é«˜çº§åº”ç”¨
    """
    
    def __init__(
        self,
        config: Config,
        max_steps: int = 15,  # å¤šæ¨¡æ€ä»»åŠ¡å¯èƒ½éœ€è¦æ›´å¤šæ­¥éª¤
        temperature: float = 0.1
    ):
        # åˆ›å»ºå·¥å…·ç®¡ç†å™¨å¹¶æ³¨å†Œå¤šæ¨¡æ€å·¥å…·
        tool_manager = self._create_multimodal_tool_manager(config)
        
        # åˆå§‹åŒ–çˆ¶ç±»
        super().__init__(
            tool_manager=tool_manager,
            max_steps=max_steps,
            model=config.openai_model,
            temperature=temperature
        )
        
        self.config = config
        self.current_image: Optional[str] = None  # å½“å‰å¤„ç†çš„å›¾åƒ
        self.multimodal_context: Dict[str, Any] = {}  # å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
        
        # é‡æ–°åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ä»¥ä½¿ç”¨é…ç½®
        self.client = AsyncOpenAI(
            api_key=config.openai_api_key,
            base_url=config.openai_base_url,
            organization=config.openai_organization
        )
        
        logger.info("å¤šæ¨¡æ€ä»£ç†åˆå§‹åŒ–å®Œæˆ")
    
    def _create_multimodal_tool_manager(self, config: Config) -> ToolManager:
        """åˆ›å»ºåŒ…å«å¤šæ¨¡æ€å·¥å…·çš„å·¥å…·ç®¡ç†å™¨"""
        tool_manager = ToolManager()
        
        # æ³¨å†ŒåŸºç¡€å·¥å…·ï¼ˆä»practical5å¤åˆ¶ï¼‰
        from ..tools.calculator import CalculatorTool
        from ..tools.text_processor import TextProcessorTool
        
        tool_manager.register_tool(CalculatorTool())
        tool_manager.register_tool(TextProcessorTool())
        
        # æ³¨å†Œå¤šæ¨¡æ€å·¥å…·
        tool_manager.register_tool(ImageAnalyzer(config))
        tool_manager.register_tool(BrowserTool(config))
        
        logger.info(f"æ³¨å†Œäº† {len(tool_manager.get_available_tools())} ä¸ªå·¥å…·")
        return tool_manager
    
    async def solve_multimodal(
        self,
        user_query: str,
        image: Optional[Union[str, Path, Image.Image, bytes]] = None,
        task_type: str = MultimodalTaskType.GENERAL
    ) -> Dict[str, Any]:
        """
        è§£å†³å¤šæ¨¡æ€é—®é¢˜
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            image: å›¾åƒè¾“å…¥ï¼ˆå¯é€‰ï¼‰
            task_type: ä»»åŠ¡ç±»å‹
            
        Returns:
            è§£å†³æ–¹æ¡ˆå’Œæ‰§è¡Œè½¨è¿¹
        """
        start_time = time.time()
        
        try:
            # é¢„å¤„ç†å¤šæ¨¡æ€è¾“å…¥
            await self._preprocess_multimodal_input(user_query, image, task_type)
            
            # æ‰§è¡ŒReActå¾ªç¯
            result = await self.solve(user_query)
            
            # åå¤„ç†ç»“æœ
            result = self._postprocess_multimodal_result(result, start_time)
            
            return result
            
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€é—®é¢˜è§£å†³å¤±è´¥: {e}")
            return self._generate_error_result(str(e), time.time() - start_time)
        finally:
            # æ¸…ç†èµ„æº
            await self._cleanup_resources()
    
    async def _preprocess_multimodal_input(
        self,
        user_query: str,
        image: Optional[Union[str, Path, Image.Image, bytes]],
        task_type: str
    ) -> None:
        """é¢„å¤„ç†å¤šæ¨¡æ€è¾“å…¥"""
        # å¤„ç†å›¾åƒè¾“å…¥
        if image is not None:
            try:
                # è·å–å›¾åƒåˆ†æå·¥å…·
                image_analyzer = self.tool_manager.get_tool("image_analyzer")
                if image_analyzer:
                    # å¤„ç†å›¾åƒä¸ºBase64æ ¼å¼
                    self.current_image = image_analyzer._prepare_image_for_api(image)
                    logger.info("å›¾åƒé¢„å¤„ç†å®Œæˆ")
            except Exception as e:
                logger.warning(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
        
        # è®¾ç½®å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
        self.multimodal_context = {
            "has_image": image is not None,
            "task_type": task_type,
            "image_processed": self.current_image is not None,
            "available_tools": self.tool_manager.get_available_tools()
        }
        
        # åˆ†æä»»åŠ¡ç±»å‹å¹¶è®¾ç½®ç­–ç•¥
        self._analyze_task_strategy(user_query, task_type)
    
    def _analyze_task_strategy(self, user_query: str, task_type: str) -> None:
        """åˆ†æä»»åŠ¡ç­–ç•¥"""
        strategy_hints = {
            MultimodalTaskType.IMAGE_ANALYSIS: "é‡ç‚¹ä½¿ç”¨å›¾åƒåˆ†æå·¥å…·",
            MultimodalTaskType.WEB_AUTOMATION: "é‡ç‚¹ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·",
            MultimodalTaskType.MULTIMODAL_SEARCH: "ç»“åˆå›¾åƒåˆ†æå’Œç½‘é¡µæœç´¢",
            MultimodalTaskType.VISUAL_WEB_TASK: "å…ˆåˆ†æå›¾åƒï¼Œå†æ‰§è¡Œç½‘é¡µæ“ä½œ",
            MultimodalTaskType.GENERAL: "æ ¹æ®éœ€è¦é€‰æ‹©åˆé€‚çš„å·¥å…·"
        }
        
        self.multimodal_context["strategy_hint"] = strategy_hints.get(
            task_type, 
            strategy_hints[MultimodalTaskType.GENERAL]
        )
    
    def _get_react_prompt(self, user_query: str) -> str:
        """
        é‡å†™ReActæç¤ºï¼Œæ·»åŠ å¤šæ¨¡æ€æ”¯æŒ
        
        æ‰©å±•åŸæœ‰æç¤ºä»¥æ”¯æŒï¼š
        1. å¤šæ¨¡æ€å·¥å…·çš„ä½¿ç”¨
        2. å›¾åƒåˆ†æç­–ç•¥
        3. æµè§ˆå™¨è‡ªåŠ¨åŒ–æŒ‡å¯¼
        """
        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„å¤šæ¨¡æ€ä»£ç†ï¼Œèƒ½å¤Ÿå¤„ç†æ–‡æœ¬å’Œå›¾åƒè¾“å…¥ï¼Œå¹¶ä½¿ç”¨å„ç§å·¥å…·æ¥è§£å†³é—®é¢˜ã€‚

ä½ éœ€è¦ä½¿ç”¨ReActï¼ˆReasoning and Actingï¼‰æ¨¡å¼æ¥è§£å†³ç”¨æˆ·çš„é—®é¢˜ï¼š
1. Thought: åˆ†æå½“å‰æƒ…å†µï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
2. Action: é€‰æ‹©å¹¶æ‰§è¡Œä¸€ä¸ªå·¥å…·
3. Observation: è§‚å¯Ÿå·¥å…·æ‰§è¡Œçš„ç»“æœ
4. é‡å¤ä¸Šè¿°è¿‡ç¨‹ç›´åˆ°æ‰¾åˆ°æœ€ç»ˆç­”æ¡ˆ

å¤šæ¨¡æ€å¤„ç†æŒ‡å¯¼ï¼š
- å¦‚æœç”¨æˆ·æä¾›äº†å›¾åƒï¼Œä¼˜å…ˆä½¿ç”¨image_analyzerå·¥å…·åˆ†æå›¾åƒå†…å®¹
- å¯¹äºç½‘é¡µç›¸å…³ä»»åŠ¡ï¼Œä½¿ç”¨browser_toolè¿›è¡Œè‡ªåŠ¨åŒ–æ“ä½œ
- å¯ä»¥ç»“åˆå¤šä¸ªå·¥å…·æ¥å®Œæˆå¤æ‚ä»»åŠ¡
- æ³¨æ„ä¿æŒä¸Šä¸‹æ–‡çš„è¿è´¯æ€§

å½“å‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
- æ˜¯å¦æœ‰å›¾åƒè¾“å…¥: {self.multimodal_context.get('has_image', False)}
- ä»»åŠ¡ç±»å‹: {self.multimodal_context.get('task_type', 'general')}
- ç­–ç•¥æç¤º: {self.multimodal_context.get('strategy_hint', '')}

å¯ç”¨å·¥å…·ï¼š
{self._get_tools_info()}

ç”¨æˆ·é—®é¢˜: {user_query}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š

Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: {{"name": "å·¥å…·åç§°", "parameters": {{å‚æ•°å­—å…¸}}}}
Observation: [ç­‰å¾…å·¥å…·æ‰§è¡Œç»“æœ]

å¦‚æœä½ å·²ç»æœ‰äº†æœ€ç»ˆç­”æ¡ˆï¼Œè¯·ä½¿ç”¨ï¼š
Thought: [æ€»ç»“æ€è€ƒ]
Final Answer: [æœ€ç»ˆç­”æ¡ˆ]

{self._get_steps_history()}

ç°åœ¨å¼€å§‹è§£å†³é—®é¢˜ï¼š"""

        return base_prompt
    
    def _get_tools_info(self) -> str:
        """è·å–å·¥å…·ä¿¡æ¯ï¼Œé‡ç‚¹çªå‡ºå¤šæ¨¡æ€å·¥å…·"""
        tools_info = []
        
        for tool_name in self.tool_manager.get_available_tools():
            tool = self.tool_manager.get_tool(tool_name)
            if tool:
                # ä¸ºå¤šæ¨¡æ€å·¥å…·æ·»åŠ ç‰¹æ®Šæ ‡è®°
                if isinstance(tool, MultimodalTool):
                    marker = "ğŸ”¥ [å¤šæ¨¡æ€å·¥å…·]"
                else:
                    marker = "ğŸ“‹ [åŸºç¡€å·¥å…·]"
                
                tools_info.append(f"{marker} {tool.name}: {tool.description}")
                
                # ä¸ºç‰¹æ®Šå·¥å…·æ·»åŠ ä½¿ç”¨æç¤º
                if tool.name == "image_analyzer":
                    tools_info.append("   ğŸ’¡ æ”¯æŒå›¾åƒæè¿°ã€OCRã€å¯¹è±¡è¯†åˆ«ç­‰åŠŸèƒ½")
                elif tool.name == "browser_tool":
                    tools_info.append("   ğŸ’¡ æ”¯æŒç½‘é¡µå¯¼èˆªã€å…ƒç´ æ“ä½œã€æˆªå›¾ç­‰åŠŸèƒ½")
        
        return "\n".join(tools_info)
    
    async def _execute_step(self, user_query: str) -> None:
        """
        é‡å†™æ­¥éª¤æ‰§è¡Œï¼Œæ”¯æŒå¤šæ¨¡æ€æ­¥éª¤è®°å½•
        """
        step_start_time = time.time()
        
        # æ„å»ºæç¤º
        prompt = self._get_react_prompt(user_query)
        
        # è°ƒç”¨LLM
        response = await self._call_llm(prompt)
        
        # è§£æå“åº”
        thought, action, final_answer = self._parse_response(response)
        
        # åˆ›å»ºå¤šæ¨¡æ€æ­¥éª¤è®°å½•
        current_step = MultimodalStep(
            step_number=len(self.steps) + 1,
            thought=thought,
            action=action,
            observation=None,
            state=AgentState.THINKING,
            image_data=self.current_image,
            task_type=self.multimodal_context.get('task_type', 'general'),
            multimodal_context=self.multimodal_context.copy()
        )
        
        # å¦‚æœæœ‰æœ€ç»ˆç­”æ¡ˆï¼Œç›´æ¥å®Œæˆ
        if final_answer:
            current_step.observation = final_answer
            current_step.state = AgentState.FINISHED
            current_step.execution_time = time.time() - step_start_time
            self.steps.append(current_step)
            self.state = AgentState.FINISHED
            self.final_answer = final_answer
            return
        
        # å¦‚æœæ²¡æœ‰è¡ŒåŠ¨ï¼Œè¿›å…¥é”™è¯¯çŠ¶æ€
        if not action:
            current_step.observation = "æ— æ³•è§£æå‡ºæœ‰æ•ˆçš„è¡ŒåŠ¨"
            current_step.state = AgentState.ERROR
            current_step.execution_time = time.time() - step_start_time
            self.steps.append(current_step)
            self.state = AgentState.ERROR
            return
        
        # æ‰§è¡Œå·¥å…·
        current_step.state = AgentState.ACTING
        try:
            # ä¸ºå¤šæ¨¡æ€å·¥å…·æ·»åŠ å›¾åƒå‚æ•°
            if self._is_multimodal_tool(action["name"]) and self.current_image:
                if "parameters" not in action:
                    action["parameters"] = {}
                action["parameters"]["image"] = self.current_image
            
            tool_result = await self._execute_tool(action)
            observation = self._format_tool_result(tool_result)
            
            current_step.observation = observation
            current_step.state = AgentState.OBSERVING
            
            # æ›´æ–°å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
            self._update_multimodal_context(action, tool_result)
            
        except Exception as e:
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            current_step.observation = f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
            current_step.state = AgentState.ERROR
            self.state = AgentState.ERROR
        
        current_step.execution_time = time.time() - step_start_time
        self.steps.append(current_step)
    
    def _is_multimodal_tool(self, tool_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ¨¡æ€å·¥å…·"""
        tool = self.tool_manager.get_tool(tool_name)
        return isinstance(tool, MultimodalTool)
    
    def _update_multimodal_context(self, action: Dict[str, Any], result: ToolResult) -> None:
        """æ›´æ–°å¤šæ¨¡æ€ä¸Šä¸‹æ–‡"""
        tool_name = action.get("name", "")
        
        # è®°å½•å·¥å…·ä½¿ç”¨å†å²
        if "tool_usage" not in self.multimodal_context:
            self.multimodal_context["tool_usage"] = []
        
        self.multimodal_context["tool_usage"].append({
            "tool": tool_name,
            "success": result.status.value == "success",
            "timestamp": time.time()
        })
        
        # ç‰¹æ®Šå¤„ç†å›¾åƒåˆ†æç»“æœ
        if tool_name == "image_analyzer" and result.data:
            self.multimodal_context["image_analysis"] = result.data
        
        # ç‰¹æ®Šå¤„ç†æµè§ˆå™¨æ“ä½œç»“æœ
        if tool_name == "browser_tool" and result.data:
            if "browser_state" not in self.multimodal_context:
                self.multimodal_context["browser_state"] = {}
            
            self.multimodal_context["browser_state"].update({
                "last_action": result.data.get("action"),
                "current_url": result.data.get("current_url"),
                "page_title": result.data.get("page_title")
            })
    
    def _postprocess_multimodal_result(
        self,
        result: Dict[str, Any],
        start_time: float
    ) -> Dict[str, Any]:
        """åå¤„ç†å¤šæ¨¡æ€ç»“æœ"""
        # æ·»åŠ å¤šæ¨¡æ€ç‰¹å®šä¿¡æ¯
        result["multimodal_info"] = {
            "had_image_input": self.multimodal_context.get("has_image", False),
            "task_type": self.multimodal_context.get("task_type", "general"),
            "tools_used": [
                usage["tool"] for usage in 
                self.multimodal_context.get("tool_usage", [])
            ],
            "image_analysis_performed": "image_analysis" in self.multimodal_context,
            "browser_automation_used": "browser_state" in self.multimodal_context
        }
        
        # æ·»åŠ æ‰§è¡Œç»Ÿè®¡
        multimodal_steps = [step for step in self.steps if isinstance(step, MultimodalStep)]
        result["execution_stats"]["multimodal_steps"] = len(multimodal_steps)
        
        return result
    
    async def _cleanup_resources(self) -> None:
        """æ¸…ç†å¤šæ¨¡æ€èµ„æº"""
        try:
            # æ¸…ç†æµè§ˆå™¨èµ„æº
            browser_tool = self.tool_manager.get_tool("browser_tool")
            if browser_tool and hasattr(browser_tool, 'close'):
                await browser_tool.close()
            
            # æ¸…ç†å›¾åƒæ•°æ®
            self.current_image = None
            self.multimodal_context.clear()
            
            logger.info("å¤šæ¨¡æ€èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"èµ„æºæ¸…ç†æ—¶å‡ºç°å¼‚å¸¸: {e}")
    
    def get_multimodal_trace(self) -> List[Dict[str, Any]]:
        """è·å–å¤šæ¨¡æ€æ‰§è¡Œè½¨è¿¹"""
        return [
            step.to_dict() for step in self.steps 
            if isinstance(step, MultimodalStep)
        ]
    
    async def analyze_image(
        self,
        image: Union[str, Path, Image.Image, bytes],
        prompt: str = "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹",
        analysis_type: str = "describe"
    ) -> Dict[str, Any]:
        """
        ä¾¿æ·çš„å›¾åƒåˆ†ææ–¹æ³•
        
        Args:
            image: å›¾åƒè¾“å…¥
            prompt: åˆ†ææç¤º
            analysis_type: åˆ†æç±»å‹
            
        Returns:
            åˆ†æç»“æœ
        """
        return await self.solve_multimodal(
            user_query=prompt,
            image=image,
            task_type=MultimodalTaskType.IMAGE_ANALYSIS
        )
    
    async def automate_browser(
        self,
        task_description: str,
        url: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä¾¿æ·çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–æ–¹æ³•
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            url: èµ·å§‹URLï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è‡ªåŠ¨åŒ–ç»“æœ
        """
        query = task_description
        if url:
            query = f"è¯·è®¿é—® {url} å¹¶æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š{task_description}"
        
        return await self.solve_multimodal(
            user_query=query,
            task_type=MultimodalTaskType.WEB_AUTOMATION
        )
    
    async def visual_web_task(
        self,
        image: Union[str, Path, Image.Image, bytes],
        task_description: str
    ) -> Dict[str, Any]:
        """
        è§†è§‰å¼•å¯¼çš„ç½‘é¡µä»»åŠ¡
        
        Args:
            image: å‚è€ƒå›¾åƒ
            task_description: ä»»åŠ¡æè¿°
            
        Returns:
            ä»»åŠ¡ç»“æœ
        """
        query = f"æ ¹æ®æä¾›çš„å›¾åƒï¼Œæ‰§è¡Œä»¥ä¸‹ç½‘é¡µä»»åŠ¡ï¼š{task_description}"
        
        return await self.solve_multimodal(
            user_query=query,
            image=image,
            task_type=MultimodalTaskType.VISUAL_WEB_TASK
        )